{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sharu\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from datetime import date\n",
    "from langchain.agents import tool\n",
    "import langchain\n",
    "from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms.bedrock import Bedrock\n",
    "# import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "llm = GoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=os.environ['GOOGLE_API_KEY'],generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "# llm=Bedrock(client=client,\n",
    "#             model_id=\"anthropic.claude-instant-v1\",\n",
    "#             model_kwargs={\n",
    "#                 \"max_tokens_to_sample\":500,\n",
    "#                 \"temperature\":0,\n",
    "#                 \"top_p\":0.9\n",
    "#             }\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool\n",
    "# def time(text: str) -> str:\n",
    "#     \"\"\"Returns todays date, use this for any \\\n",
    "#     questions related to knowing todays date. \\\n",
    "#     The input should always be an empty string, \\\n",
    "#     and this function will always return todays \\\n",
    "#     date.\"\"\"\n",
    "#     # return str(date.today())\n",
    "#     return str(\"hai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template_string\n",
    "import threading\n",
    "app = Flask(__name__)\n",
    "thread=None\n",
    "\n",
    "@tool\n",
    "def host_webpage(html_content):\n",
    "    \"\"\"\n",
    "    Returns the link where question webpage hosted, use this after \\\n",
    "    questions are generated in html form format. \\\n",
    "    The input should always be an html form code, \\\n",
    "    and this function will always return link to webpage hosted  \\\n",
    "    \"\"\"\n",
    "\n",
    "    @app.route('/')\n",
    "    def display_html():\n",
    "        return render_template_string(html_content)\n",
    "\n",
    "    def run_app():\n",
    "        app.run(host='localhost', port=5000, debug=False)\n",
    "\n",
    "    # Start Flask in a separate thread\n",
    "    global thread\n",
    "    thread = threading.Thread(target=run_app)\n",
    "    thread.start()\n",
    "\n",
    "    # Return the link to the page\n",
    "    return \"http://localhost:5000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_revelent_context(topic: str) -> str:\n",
    "    \"\"\"Returns the relevent context to generate questions, use this after \\\n",
    "    the user have choosed the topic to generate questions. \\\n",
    "    The input should always be an topic that user mentioned, \\\n",
    "    and this function will always return context string  \\\n",
    "    \"\"\"\n",
    "    \n",
    "    relevent_doc=vectordb.similarity_search(topic,k=5)\n",
    "    context=\"\\n\\n\".join([doc.page_content for doc in relevent_doc])\n",
    "\n",
    "    return str(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_topics_from_uploaded_document(text: str) -> str:\n",
    "    \"\"\"Returns the topics in the uploaded documents, use this after \\\n",
    "    document loaded successfully. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return string of topics \\\n",
    "    .\"\"\"\n",
    "    # return str(date.today())\n",
    "    return str(\"aws workflows, aws redshift copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def upload_doc(text: str) -> str:\n",
    "    \"\"\"loads the document to memory. Use only when user mentioned i want to upload something\\\n",
    "       or else don't use.The input should always be an empty string. \\\n",
    "       and this function always returns status of the upload.\"\"\"\n",
    "    # return str(date.today())\n",
    "\n",
    "    path=input(\"please enter path\")\n",
    "    print(\"Loading the data.....\")\n",
    "    loader = PyPDFLoader(path)\n",
    "    data = loader.load()\n",
    "    docs=text_splitter.split_documents(data)\n",
    "    global vectordb \n",
    "    vectordb= Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        # persist_directory='docs/chroma/'\n",
    "    )\n",
    "    return str(\"uploaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[upload_doc,get_topics_from_uploaded_document,get_revelent_context,host_webpage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAT_CONVERSATIONAL_REACT_DESCRIPTION',\n",
       " 'CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
       " 'CONVERSATIONAL_REACT_DESCRIPTION',\n",
       " 'OPENAI_FUNCTIONS',\n",
       " 'OPENAI_MULTI_FUNCTIONS',\n",
       " 'REACT_DOCSTORE',\n",
       " 'SELF_ASK_WITH_SEARCH',\n",
       " 'STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
       " 'ZERO_SHOT_REACT_DESCRIPTION',\n",
       " '__class__',\n",
       " '__doc__',\n",
       " '__members__',\n",
       " '__module__']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(AgentType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sharu\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    conversational=True,\n",
    "    max_iterations=5,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\" \n",
    "Assistant is a large language model trained by OpenAI.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\n",
    "You are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\n",
    "always follow these steps:\n",
    "\n",
    "1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\n",
    "2. Based on the chosen source, take the appropriate action:\n",
    "    - Upload: Call `upload_doc` with the user-uploaded document.\n",
    "    - URL: Access the web page and extract content.\n",
    "    - Text: Use the provided text directly.\n",
    "3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\n",
    "4. Ask for the Topic and generate 5 Question on the selected topic.\n",
    "5. Generate questions in a HTML form format.\n",
    "6. Call `host_webpage` with the generated HTML code and provide the link to the user.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.agent.llm_chain.prompt.messages[0].prompt.template=template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "You are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\n",
      "always follow these steps:\n",
      "\n",
      "1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\n",
      "2. Based on the chosen source, take the appropriate action:\n",
      "    - Upload: Call `upload_doc` with the user-uploaded document.\n",
      "    - URL: Access the web page and extract content.\n",
      "    - Text: Use the provided text directly.\n",
      "3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\n",
      "4. Ask for the Topic and generate 5 Question on the selected topic.\n",
      "5. Generate questions in a HTML form format.\n",
      "6. Call `host_webpage` with the generated HTML code and provide the link to the user.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sharu\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"hi\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"hi\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nhi\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [2.48s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [2.48s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [2.50s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chat_history=[]\n",
    "response=agent({\"input\": \"hi\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=response['input']),\n",
    "        AIMessage(content=response[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi'),\n",
       " AIMessage(content='Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\ni want to upload a document\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [908ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"upload_doc\\\",\\n    \\\"action_input\\\": \\\"\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [910ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"upload_doc\\\",\\n    \\\"action_input\\\": \\\"\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:upload_doc] Entering Tool run with input:\n",
      "\u001b[0m\"\"\n",
      "Loading the data.....\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:upload_doc] [60.44s] Exiting Tool run with output:\n",
      "\u001b[0m\"uploaded successfully\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\ni want to upload a document\\nAI: ```json\\n{\\n    \\\"action\\\": \\\"upload_doc\\\",\\n    \\\"action_input\\\": \\\"\\\"\\n}\\n```\\nHuman: TOOL RESPONSE: \\n---------------------\\nuploaded successfully\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [1.30s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.30s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [62.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response=agent({\"input\": \"i want to upload a document\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=response['input']),\n",
    "        AIMessage(content=response[\"output\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi'),\n",
       " AIMessage(content='Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?'),\n",
       " HumanMessage(content='i want to upload a document'),\n",
       " AIMessage(content=\"Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\")]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nwhat are the topics available in document\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [945ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"get_topics_from_uploaded_document\\\",\\n    \\\"action_input\\\": \\\"\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [945ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"get_topics_from_uploaded_document\\\",\\n    \\\"action_input\\\": \\\"\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:get_topics_from_uploaded_document] Entering Tool run with input:\n",
      "\u001b[0m\"\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:get_topics_from_uploaded_document] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"aws workflows, aws redshift copy\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nwhat are the topics available in document\\nAI: ```json\\n{\\n    \\\"action\\\": \\\"get_topics_from_uploaded_document\\\",\\n    \\\"action_input\\\": \\\"\\\"\\n}\\n```\\nHuman: TOOL RESPONSE: \\n---------------------\\naws workflows, aws redshift copy\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [1.12s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"The topics available in the document are: aws workflows, aws redshift copy.\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.12s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"The topics available in the document are: aws workflows, aws redshift copy.\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [2.07s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The topics available in the document are: aws workflows, aws redshift copy.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response=agent({\"input\": \"what are the topics available in document\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=response['input']),\n",
    "        AIMessage(content=response[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi'),\n",
       " AIMessage(content='Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?'),\n",
       " HumanMessage(content='i want to upload a document'),\n",
       " AIMessage(content=\"Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\"),\n",
       " HumanMessage(content='what are the topics available in document'),\n",
       " AIMessage(content='The topics available in the document are: aws workflows, aws redshift copy.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: what are the topics available in document\\nAI: The topics available in the document are: aws workflows, aws redshift copy.\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nOkay generate mcq questions on aws workflows\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [913ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"get_revelent_context\\\",\\n    \\\"action_input\\\": \\\"aws workflows\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [917ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"get_revelent_context\\\",\\n    \\\"action_input\\\": \\\"aws workflows\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:get_revelent_context] Entering Tool run with input:\n",
      "\u001b[0m\"aws workflows\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:get_revelent_context] [375ms] Exiting Tool run with output:\n",
      "\u001b[0m\"service for Apache Airflow so you \n",
      "don’t have to deal with installing or \n",
      "maintaining it\n",
      "•Use cases:\n",
      "•Complex workflows\n",
      "•ETL coordination\n",
      "•Preparing ML data\n",
      "Amazon Managed Workflows \n",
      "for Apache Airflow\n",
      "\n",
      "sundog -education.com\n",
      "datacumulus.com\n",
      "© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \n",
      "Amazon Managed Workflows for Apache \n",
      "Airflow (MWAA)\n",
      "•Apache Airflow is batch -oriented \n",
      "workflow tool\n",
      "•Develop, schedule, and monitor your \n",
      "workflows\n",
      "•Workflows are defined as Python \n",
      "code that creates a Directed Acyclic \n",
      "Graph (DAG)\n",
      "•Amazon MWAA provides a managed \n",
      "service for Apache Airflow so you \n",
      "don’t have to deal with installing or \n",
      "maintaining it\n",
      "\n",
      "sundog -education.com\n",
      "datacumulus.com\n",
      "© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \n",
      "AWS Step Functions\n",
      "•Your workflow is called a state machine\n",
      "•Each step in a workflow is a state\n",
      "•Types of states\n",
      "•Task : Does something with Lambda, other \n",
      "AWS services, or third party API’s\n",
      "•Choice : Adds conditional logic via Choice \n",
      "Rules ( ie, comparisons)\n",
      "•Wait: Delays state machine for a specified \n",
      "time\n",
      "•Parallel : Add separate branches of \n",
      "execution\n",
      "\n",
      "•Private or public endpoints\n",
      "•IAM-managed\n",
      "•(Access to Airflow Web Server)\n",
      "•Automatic scaling\n",
      "•Airflow Workers autoscale  up to the \n",
      "limits you defineAmazon Managed Workflows \n",
      "for Apache Airflow\n",
      "Amazon Simple Storage \n",
      "Service (Amazon S3)Everything! ETL, ML, analytics, \n",
      "storage, databases…\n",
      "\n",
      "sundog -education.com\n",
      "datacumulus.com\n",
      "© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \n",
      "Managing ETL Pipelines\n",
      "•This process must be \n",
      "automated in some reliable way\n",
      "•AWS Glue\n",
      "•Orchestration services\n",
      "•EventBridge\n",
      "• Amazon Managed Workflows for \n",
      "Apache Airflow [Amazon MWAA]\n",
      "•AWS Step Functions\n",
      "•Lambda\n",
      "•Glue Workflows\n",
      "•We’ll get into specific \n",
      "architectures later.\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: what are the topics available in document\\nAI: The topics available in the document are: aws workflows, aws redshift copy.\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nOkay generate mcq questions on aws workflows\\nAI: ```json\\n{\\n    \\\"action\\\": \\\"get_revelent_context\\\",\\n    \\\"action_input\\\": \\\"aws workflows\\\"\\n}\\n```\\nHuman: TOOL RESPONSE: \\n---------------------\\nservice for Apache Airflow so you \\ndon’t have to deal with installing or \\nmaintaining it\\n•Use cases:\\n•Complex workflows\\n•ETL coordination\\n•Preparing ML data\\nAmazon Managed Workflows \\nfor Apache Airflow\\n\\nsundog -education.com\\ndatacumulus.com\\n© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \\nAmazon Managed Workflows for Apache \\nAirflow (MWAA)\\n•Apache Airflow is batch -oriented \\nworkflow tool\\n•Develop, schedule, and monitor your \\nworkflows\\n•Workflows are defined as Python \\ncode that creates a Directed Acyclic \\nGraph (DAG)\\n•Amazon MWAA provides a managed \\nservice for Apache Airflow so you \\ndon’t have to deal with installing or \\nmaintaining it\\n\\nsundog -education.com\\ndatacumulus.com\\n© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \\nAWS Step Functions\\n•Your workflow is called a state machine\\n•Each step in a workflow is a state\\n•Types of states\\n•Task : Does something with Lambda, other \\nAWS services, or third party API’s\\n•Choice : Adds conditional logic via Choice \\nRules ( ie, comparisons)\\n•Wait: Delays state machine for a specified \\ntime\\n•Parallel : Add separate branches of \\nexecution\\n\\n•Private or public endpoints\\n•IAM-managed\\n•(Access to Airflow Web Server)\\n•Automatic scaling\\n•Airflow Workers autoscale  up to the \\nlimits you defineAmazon Managed Workflows \\nfor Apache Airflow\\nAmazon Simple Storage \\nService (Amazon S3)Everything! ETL, ML, analytics, \\nstorage, databases…\\n\\nsundog -education.com\\ndatacumulus.com\\n© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \\nManaging ETL Pipelines\\n•This process must be \\nautomated in some reliable way\\n•AWS Glue\\n•Orchestration services\\n•EventBridge\\n• Amazon Managed Workflows for \\nApache Airflow [Amazon MWAA]\\n•AWS Step Functions\\n•Lambda\\n•Glue Workflows\\n•We’ll get into specific \\narchitectures later.\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [1.65s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.66s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [2.98s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response=agent({\"input\": \"Okay generate mcq questions on aws workflows\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=response['input']),\n",
    "        AIMessage(content=response[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi'),\n",
       " AIMessage(content='Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?'),\n",
       " HumanMessage(content='i want to upload a document'),\n",
       " AIMessage(content=\"Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\"),\n",
       " HumanMessage(content='what are the topics available in document'),\n",
       " AIMessage(content='The topics available in the document are: aws workflows, aws redshift copy.'),\n",
       " HumanMessage(content='Okay generate mcq questions on aws workflows'),\n",
       " AIMessage(content='Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: what are the topics available in document\\nAI: The topics available in the document are: aws workflows, aws redshift copy.\\nHuman: Okay generate mcq questions on aws workflows\\nAI: Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\ncan you generate mcq's on the same\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [924ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"get_revelent_context\\\",\\n    \\\"action_input\\\": \\\"aws workflows\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [927ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"get_revelent_context\\\",\\n    \\\"action_input\\\": \\\"aws workflows\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:get_revelent_context] Entering Tool run with input:\n",
      "\u001b[0m\"aws workflows\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:get_revelent_context] [396ms] Exiting Tool run with output:\n",
      "\u001b[0m\"service for Apache Airflow so you \n",
      "don’t have to deal with installing or \n",
      "maintaining it\n",
      "•Use cases:\n",
      "•Complex workflows\n",
      "•ETL coordination\n",
      "•Preparing ML data\n",
      "Amazon Managed Workflows \n",
      "for Apache Airflow\n",
      "\n",
      "sundog -education.com\n",
      "datacumulus.com\n",
      "© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \n",
      "Amazon Managed Workflows for Apache \n",
      "Airflow (MWAA)\n",
      "•Apache Airflow is batch -oriented \n",
      "workflow tool\n",
      "•Develop, schedule, and monitor your \n",
      "workflows\n",
      "•Workflows are defined as Python \n",
      "code that creates a Directed Acyclic \n",
      "Graph (DAG)\n",
      "•Amazon MWAA provides a managed \n",
      "service for Apache Airflow so you \n",
      "don’t have to deal with installing or \n",
      "maintaining it\n",
      "\n",
      "sundog -education.com\n",
      "datacumulus.com\n",
      "© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \n",
      "AWS Step Functions\n",
      "•Your workflow is called a state machine\n",
      "•Each step in a workflow is a state\n",
      "•Types of states\n",
      "•Task : Does something with Lambda, other \n",
      "AWS services, or third party API’s\n",
      "•Choice : Adds conditional logic via Choice \n",
      "Rules ( ie, comparisons)\n",
      "•Wait: Delays state machine for a specified \n",
      "time\n",
      "•Parallel : Add separate branches of \n",
      "execution\n",
      "\n",
      "•Private or public endpoints\n",
      "•IAM-managed\n",
      "•(Access to Airflow Web Server)\n",
      "•Automatic scaling\n",
      "•Airflow Workers autoscale  up to the \n",
      "limits you defineAmazon Managed Workflows \n",
      "for Apache Airflow\n",
      "Amazon Simple Storage \n",
      "Service (Amazon S3)Everything! ETL, ML, analytics, \n",
      "storage, databases…\n",
      "\n",
      "sundog -education.com\n",
      "datacumulus.com\n",
      "© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \n",
      "Managing ETL Pipelines\n",
      "•This process must be \n",
      "automated in some reliable way\n",
      "•AWS Glue\n",
      "•Orchestration services\n",
      "•EventBridge\n",
      "• Amazon Managed Workflows for \n",
      "Apache Airflow [Amazon MWAA]\n",
      "•AWS Step Functions\n",
      "•Lambda\n",
      "•Glue Workflows\n",
      "•We’ll get into specific \n",
      "architectures later.\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: what are the topics available in document\\nAI: The topics available in the document are: aws workflows, aws redshift copy.\\nHuman: Okay generate mcq questions on aws workflows\\nAI: Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\ncan you generate mcq's on the same\\nAI: ```json\\n{\\n    \\\"action\\\": \\\"get_revelent_context\\\",\\n    \\\"action_input\\\": \\\"aws workflows\\\"\\n}\\n```\\nHuman: TOOL RESPONSE: \\n---------------------\\nservice for Apache Airflow so you \\ndon’t have to deal with installing or \\nmaintaining it\\n•Use cases:\\n•Complex workflows\\n•ETL coordination\\n•Preparing ML data\\nAmazon Managed Workflows \\nfor Apache Airflow\\n\\nsundog -education.com\\ndatacumulus.com\\n© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \\nAmazon Managed Workflows for Apache \\nAirflow (MWAA)\\n•Apache Airflow is batch -oriented \\nworkflow tool\\n•Develop, schedule, and monitor your \\nworkflows\\n•Workflows are defined as Python \\ncode that creates a Directed Acyclic \\nGraph (DAG)\\n•Amazon MWAA provides a managed \\nservice for Apache Airflow so you \\ndon’t have to deal with installing or \\nmaintaining it\\n\\nsundog -education.com\\ndatacumulus.com\\n© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \\nAWS Step Functions\\n•Your workflow is called a state machine\\n•Each step in a workflow is a state\\n•Types of states\\n•Task : Does something with Lambda, other \\nAWS services, or third party API’s\\n•Choice : Adds conditional logic via Choice \\nRules ( ie, comparisons)\\n•Wait: Delays state machine for a specified \\ntime\\n•Parallel : Add separate branches of \\nexecution\\n\\n•Private or public endpoints\\n•IAM-managed\\n•(Access to Airflow Web Server)\\n•Automatic scaling\\n•Airflow Workers autoscale  up to the \\nlimits you defineAmazon Managed Workflows \\nfor Apache Airflow\\nAmazon Simple Storage \\nService (Amazon S3)Everything! ETL, ML, analytics, \\nstorage, databases…\\n\\nsundog -education.com\\ndatacumulus.com\\n© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \\nManaging ETL Pipelines\\n•This process must be \\nautomated in some reliable way\\n•AWS Glue\\n•Orchestration services\\n•EventBridge\\n• Amazon Managed Workflows for \\nApache Airflow [Amazon MWAA]\\n•AWS Step Functions\\n•Lambda\\n•Glue Workflows\\n•We’ll get into specific \\narchitectures later.\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [1.29s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.29s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [2.63s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response=agent({\"input\": \"can you generate mcq's on the same\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=response['input']),\n",
    "        AIMessage(content=response[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi'),\n",
       " AIMessage(content='Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?'),\n",
       " HumanMessage(content='i want to upload a document'),\n",
       " AIMessage(content=\"Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\"),\n",
       " HumanMessage(content='what are the topics available in document'),\n",
       " AIMessage(content='The topics available in the document are: aws workflows, aws redshift copy.'),\n",
       " HumanMessage(content='Okay generate mcq questions on aws workflows'),\n",
       " AIMessage(content='Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.'),\n",
       " HumanMessage(content=\"can you generate mcq's on the same\"),\n",
       " AIMessage(content=\"Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\")]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: what are the topics available in document\\nAI: The topics available in the document are: aws workflows, aws redshift copy.\\nHuman: Okay generate mcq questions on aws workflows\\nAI: Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\\nHuman: can you generate mcq's on the same\\nAI: Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\ngenerate medium type mcq's\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [1.25s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Okay, I can generate medium-difficulty MCQs on AWS Workflows.  To make sure I create the most relevant questions, could you tell me specifically what 'TOOLS' you want to focus on within AWS Workflows?  For example, are you interested in tools for managing workflows, monitoring workflows, or deploying workflows?\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.25s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Okay, I can generate medium-difficulty MCQs on AWS Workflows.  To make sure I create the most relevant questions, could you tell me specifically what 'TOOLS' you want to focus on within AWS Workflows?  For example, are you interested in tools for managing workflows, monitoring workflows, or deploying workflows?\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [1.26s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Okay, I can generate medium-difficulty MCQs on AWS Workflows.  To make sure I create the most relevant questions, could you tell me specifically what 'TOOLS' you want to focus on within AWS Workflows?  For example, are you interested in tools for managing workflows, monitoring workflows, or deploying workflows?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response=agent({\"input\": \"generate medium type mcq's\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=response['input']),\n",
    "        AIMessage(content=response[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi'),\n",
       " AIMessage(content='Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?'),\n",
       " HumanMessage(content='i want to upload a document'),\n",
       " AIMessage(content=\"Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\"),\n",
       " HumanMessage(content='what are the topics available in document'),\n",
       " AIMessage(content='The topics available in the document are: aws workflows, aws redshift copy.'),\n",
       " HumanMessage(content='Okay generate mcq questions on aws workflows'),\n",
       " AIMessage(content='Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.'),\n",
       " HumanMessage(content=\"can you generate mcq's on the same\"),\n",
       " AIMessage(content=\"Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\"),\n",
       " HumanMessage(content=\"generate medium type mcq's\"),\n",
       " AIMessage(content=\"Okay, I can generate medium-difficulty MCQs on AWS Workflows.  To make sure I create the most relevant questions, could you tell me specifically what 'TOOLS' you want to focus on within AWS Workflows?  For example, are you interested in tools for managing workflows, monitoring workflows, or deploying workflows?\")]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: what are the topics available in document\\nAI: The topics available in the document are: aws workflows, aws redshift copy.\\nHuman: Okay generate mcq questions on aws workflows\\nAI: Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\\nHuman: can you generate mcq's on the same\\nAI: Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\\nHuman: generate medium type mcq's\\nAI: Okay, I can generate medium-difficulty MCQs on AWS Workflows.  To make sure I create the most relevant questions, could you tell me specifically what 'TOOLS' you want to focus on within AWS Workflows?  For example, are you interested in tools for managing workflows, monitoring workflows, or deploying workflows?\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nget revelent context and generate\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [1.11s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"get_revelent_context\\\",\\n    \\\"action_input\\\": \\\"TOOLS\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.11s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"get_revelent_context\\\",\\n    \\\"action_input\\\": \\\"TOOLS\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:get_revelent_context] Entering Tool run with input:\n",
      "\u001b[0m\"TOOLS\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:get_revelent_context] [561ms] Exiting Tool run with output:\n",
      "\u001b[0m\"sundog -education.com\n",
      "datacumulus.com\n",
      "© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \n",
      "Services we’ll learn\n",
      "DEVELOPER TOOLS\n",
      "AWS Command Line \n",
      "Interface (AWS CLI)\n",
      "AWS Cloud9\n",
      " AWS Cloud Development Kit \n",
      "(AWS CDK)\n",
      "AWS CodeBuild\n",
      " AWS CodeCommit\n",
      " AWS CodeDeploy\n",
      "AWS CodePipelineFRONTEND WEB\n",
      "Amazon API Gateway\n",
      "MACHINE\n",
      "LEARNING\n",
      "Amazon SageMakerMANAGEMENT\n",
      "AND GOVERNANCE\n",
      "AWS CloudFormation\n",
      " AWS CloudTrail\n",
      " Amazon CloudWatch\n",
      "AWS Config Amazon \n",
      "Managed Grafana\n",
      "\n",
      "AWS CloudFormation\n",
      " AWS CloudTrail\n",
      " Amazon CloudWatch\n",
      "AWS Config Amazon \n",
      "Managed Grafana\n",
      "AWS Well -Architected Tool\n",
      "AWS Systems \n",
      "Manager\n",
      "\n",
      "Go, Node.js, C++)\n",
      "•Mobile SDKs (Android, iOS, …)\n",
      "•IoT Device SDKs (Embedded C, Arduino, …)\n",
      "•Example: AWS CLI is built on AWS SDK for \n",
      "PythonAWS SDK\n",
      "Your Application\n",
      "\n",
      "with different technologies.\n",
      "•For human -readable and editable data \n",
      "storage.\n",
      "•Importing/Exporting data from databases \n",
      "or spreadsheets.\n",
      "•Systems:  Databases (SQL -based), Excel, \n",
      "Pandas in Python, R, many ETL tools.\n",
      "\n",
      "•Don’t re -invent the wheel\n",
      "•Leverage existing templates on the web!\n",
      "•Leverage the documentation\n",
      "•Supports (almost) all AWS resources:\n",
      "•Everything we’ll see in this course is supported\n",
      "•You can use “custom resources” for resources that are not supported\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: what are the topics available in document\\nAI: The topics available in the document are: aws workflows, aws redshift copy.\\nHuman: Okay generate mcq questions on aws workflows\\nAI: Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\\nHuman: can you generate mcq's on the same\\nAI: Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\\nHuman: generate medium type mcq's\\nAI: Okay, I can generate medium-difficulty MCQs on AWS Workflows.  To make sure I create the most relevant questions, could you tell me specifically what 'TOOLS' you want to focus on within AWS Workflows?  For example, are you interested in tools for managing workflows, monitoring workflows, or deploying workflows?\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nget revelent context and generate\\nAI: ```json\\n{\\n    \\\"action\\\": \\\"get_revelent_context\\\",\\n    \\\"action_input\\\": \\\"TOOLS\\\"\\n}\\n```\\nHuman: TOOL RESPONSE: \\n---------------------\\nsundog -education.com\\ndatacumulus.com\\n© 2023 All Rights Reserved WorldwideNOT FOR DISTRIBUTION © Stephane Maarek www.datacumulus.com  \\nServices we’ll learn\\nDEVELOPER TOOLS\\nAWS Command Line \\nInterface (AWS CLI)\\nAWS Cloud9\\n AWS Cloud Development Kit \\n(AWS CDK)\\nAWS CodeBuild\\n AWS CodeCommit\\n AWS CodeDeploy\\nAWS CodePipelineFRONTEND WEB\\nAmazon API Gateway\\nMACHINE\\nLEARNING\\nAmazon SageMakerMANAGEMENT\\nAND GOVERNANCE\\nAWS CloudFormation\\n AWS CloudTrail\\n Amazon CloudWatch\\nAWS Config Amazon \\nManaged Grafana\\n\\nAWS CloudFormation\\n AWS CloudTrail\\n Amazon CloudWatch\\nAWS Config Amazon \\nManaged Grafana\\nAWS Well -Architected Tool\\nAWS Systems \\nManager\\n\\nGo, Node.js, C++)\\n•Mobile SDKs (Android, iOS, …)\\n•IoT Device SDKs (Embedded C, Arduino, …)\\n•Example: AWS CLI is built on AWS SDK for \\nPythonAWS SDK\\nYour Application\\n\\nwith different technologies.\\n•For human -readable and editable data \\nstorage.\\n•Importing/Exporting data from databases \\nor spreadsheets.\\n•Systems:  Databases (SQL -based), Excel, \\nPandas in Python, R, many ETL tools.\\n\\n•Don’t re -invent the wheel\\n•Leverage existing templates on the web!\\n•Leverage the documentation\\n•Supports (almost) all AWS resources:\\n•Everything we’ll see in this course is supported\\n•You can use “custom resources” for resources that are not supported\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [3.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Sure, here are some medium-difficulty multiple-choice questions about AWS Workflows tools.  Remember, these questions are based on the context of AWS Workflows tools and their use in managing, monitoring, and deploying workflows.\\\\n\\\\n1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments? \\\\n   a) AWS CloudFormation\\\\n   b) AWS CodeDeploy\\\\n   c) AWS CodePipeline\\\\n   d) AWS CloudTrail\\\\n\\\\n2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications? \\\\n   a) AWS CodeBuild\\\\n   b) AWS CodeCommit\\\\n   c) AWS CodePipeline\\\\n   d) AWS CloudFormation\\\\n\\\\n3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location? \\\\n   a) AWS CloudTrail\\\\n   b) AWS CloudWatch\\\\n   c) AWS Config\\\\n   d) AWS CloudFormation\\\\n\\\\n4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud? \\\\n   a) AWS Cloud9\\\\n   b) AWS CodeBuild\\\\n   c) AWS CodeCommit\\\\n   d) AWS CodeDeploy\\\\n\\\\n5. Which AWS tool allows you to define infrastructure as code using a declarative programming model? \\\\n   a) AWS CloudFormation\\\\n   b) AWS CodeDeploy\\\\n   c) AWS CodePipeline\\\\n   d) AWS CloudWatch\\\\n\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [3.63s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"Sure, here are some medium-difficulty multiple-choice questions about AWS Workflows tools.  Remember, these questions are based on the context of AWS Workflows tools and their use in managing, monitoring, and deploying workflows.\\\\n\\\\n1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments? \\\\n   a) AWS CloudFormation\\\\n   b) AWS CodeDeploy\\\\n   c) AWS CodePipeline\\\\n   d) AWS CloudTrail\\\\n\\\\n2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications? \\\\n   a) AWS CodeBuild\\\\n   b) AWS CodeCommit\\\\n   c) AWS CodePipeline\\\\n   d) AWS CloudFormation\\\\n\\\\n3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location? \\\\n   a) AWS CloudTrail\\\\n   b) AWS CloudWatch\\\\n   c) AWS Config\\\\n   d) AWS CloudFormation\\\\n\\\\n4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud? \\\\n   a) AWS Cloud9\\\\n   b) AWS CodeBuild\\\\n   c) AWS CodeCommit\\\\n   d) AWS CodeDeploy\\\\n\\\\n5. Which AWS tool allows you to define infrastructure as code using a declarative programming model? \\\\n   a) AWS CloudFormation\\\\n   b) AWS CodeDeploy\\\\n   c) AWS CodePipeline\\\\n   d) AWS CloudWatch\\\\n\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [5.32s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Sure, here are some medium-difficulty multiple-choice questions about AWS Workflows tools.  Remember, these questions are based on the context of AWS Workflows tools and their use in managing, monitoring, and deploying workflows.\\n\\n1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments? \\n   a) AWS CloudFormation\\n   b) AWS CodeDeploy\\n   c) AWS CodePipeline\\n   d) AWS CloudTrail\\n\\n2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications? \\n   a) AWS CodeBuild\\n   b) AWS CodeCommit\\n   c) AWS CodePipeline\\n   d) AWS CloudFormation\\n\\n3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location? \\n   a) AWS CloudTrail\\n   b) AWS CloudWatch\\n   c) AWS Config\\n   d) AWS CloudFormation\\n\\n4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud? \\n   a) AWS Cloud9\\n   b) AWS CodeBuild\\n   c) AWS CodeCommit\\n   d) AWS CodeDeploy\\n\\n5. Which AWS tool allows you to define infrastructure as code using a declarative programming model? \\n   a) AWS CloudFormation\\n   b) AWS CodeDeploy\\n   c) AWS CodePipeline\\n   d) AWS CloudWatch\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response=agent({\"input\": \"get revelent context and generate\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=response['input']),\n",
    "        AIMessage(content=response[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi'),\n",
       " AIMessage(content='Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?'),\n",
       " HumanMessage(content='i want to upload a document'),\n",
       " AIMessage(content=\"Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\"),\n",
       " HumanMessage(content='what are the topics available in document'),\n",
       " AIMessage(content='The topics available in the document are: aws workflows, aws redshift copy.'),\n",
       " HumanMessage(content='Okay generate mcq questions on aws workflows'),\n",
       " AIMessage(content='Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.'),\n",
       " HumanMessage(content=\"can you generate mcq's on the same\"),\n",
       " AIMessage(content=\"Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\"),\n",
       " HumanMessage(content=\"generate medium type mcq's\"),\n",
       " AIMessage(content=\"Okay, I can generate medium-difficulty MCQs on AWS Workflows.  To make sure I create the most relevant questions, could you tell me specifically what 'TOOLS' you want to focus on within AWS Workflows?  For example, are you interested in tools for managing workflows, monitoring workflows, or deploying workflows?\"),\n",
       " HumanMessage(content='get revelent context and generate'),\n",
       " AIMessage(content='Sure, here are some medium-difficulty multiple-choice questions about AWS Workflows tools.  Remember, these questions are based on the context of AWS Workflows tools and their use in managing, monitoring, and deploying workflows.\\n\\n1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments? \\n   a) AWS CloudFormation\\n   b) AWS CodeDeploy\\n   c) AWS CodePipeline\\n   d) AWS CloudTrail\\n\\n2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications? \\n   a) AWS CodeBuild\\n   b) AWS CodeCommit\\n   c) AWS CodePipeline\\n   d) AWS CloudFormation\\n\\n3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location? \\n   a) AWS CloudTrail\\n   b) AWS CloudWatch\\n   c) AWS Config\\n   d) AWS CloudFormation\\n\\n4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud? \\n   a) AWS Cloud9\\n   b) AWS CodeBuild\\n   c) AWS CodeCommit\\n   d) AWS CodeDeploy\\n\\n5. Which AWS tool allows you to define infrastructure as code using a declarative programming model? \\n   a) AWS CloudFormation\\n   b) AWS CodeDeploy\\n   c) AWS CodePipeline\\n   d) AWS CloudWatch\\n')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: what are the topics available in document\\nAI: The topics available in the document are: aws workflows, aws redshift copy.\\nHuman: Okay generate mcq questions on aws workflows\\nAI: Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\\nHuman: can you generate mcq's on the same\\nAI: Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\\nHuman: generate medium type mcq's\\nAI: Okay, I can generate medium-difficulty MCQs on AWS Workflows.  To make sure I create the most relevant questions, could you tell me specifically what 'TOOLS' you want to focus on within AWS Workflows?  For example, are you interested in tools for managing workflows, monitoring workflows, or deploying workflows?\\nHuman: get revelent context and generate\\nAI: Sure, here are some medium-difficulty multiple-choice questions about AWS Workflows tools.  Remember, these questions are based on the context of AWS Workflows tools and their use in managing, monitoring, and deploying workflows.\\n\\n1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments? \\n   a) AWS CloudFormation\\n   b) AWS CodeDeploy\\n   c) AWS CodePipeline\\n   d) AWS CloudTrail\\n\\n2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications? \\n   a) AWS CodeBuild\\n   b) AWS CodeCommit\\n   c) AWS CodePipeline\\n   d) AWS CloudFormation\\n\\n3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location? \\n   a) AWS CloudTrail\\n   b) AWS CloudWatch\\n   c) AWS Config\\n   d) AWS CloudFormation\\n\\n4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud? \\n   a) AWS Cloud9\\n   b) AWS CodeBuild\\n   c) AWS CodeCommit\\n   d) AWS CodeDeploy\\n\\n5. Which AWS tool allows you to define infrastructure as code using a declarative programming model? \\n   a) AWS CloudFormation\\n   b) AWS CodeDeploy\\n   c) AWS CodePipeline\\n   d) AWS CloudWatch\\n\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\ncan you host the same on webpage\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [5.85s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"host_webpage\\\",\\n    \\\"action_input\\\": \\\"<!DOCTYPE html>\\\\n<html>\\\\n<head>\\\\n<title>AWS Workflows MCQ's</title>\\\\n</head>\\\\n<body>\\\\n<h1>AWS Workflows MCQ's</h1>\\\\n<form>\\\\n<h2>1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CloudFormation\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeDeploy\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodePipeline\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudTrail<br>\\\\n<h2>2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CodeBuild\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeCommit\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodePipeline\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudFormation<br>\\\\n<h2>3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CloudTrail\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CloudWatch\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS Config\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudFormation<br>\\\\n<h2>4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS Cloud9\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeBuild\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodeCommit\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CodeDeploy<br>\\\\n<h2>5. Which AWS tool allows you to define infrastructure as code using a declarative programming model?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CloudFormation\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeDeploy\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodePipeline\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudWatch<br>\\\\n<input type=\\\\\\\"submit\\\\\\\" value=\\\\\\\"Submit\\\\\\\">\\\\n</form>\\\\n</body>\\\\n</html>\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [5.85s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"host_webpage\\\",\\n    \\\"action_input\\\": \\\"<!DOCTYPE html>\\\\n<html>\\\\n<head>\\\\n<title>AWS Workflows MCQ's</title>\\\\n</head>\\\\n<body>\\\\n<h1>AWS Workflows MCQ's</h1>\\\\n<form>\\\\n<h2>1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CloudFormation\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeDeploy\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodePipeline\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudTrail<br>\\\\n<h2>2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CodeBuild\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeCommit\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodePipeline\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudFormation<br>\\\\n<h2>3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CloudTrail\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CloudWatch\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS Config\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudFormation<br>\\\\n<h2>4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS Cloud9\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeBuild\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodeCommit\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CodeDeploy<br>\\\\n<h2>5. Which AWS tool allows you to define infrastructure as code using a declarative programming model?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CloudFormation\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeDeploy\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodePipeline\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudWatch<br>\\\\n<input type=\\\\\\\"submit\\\\\\\" value=\\\\\\\"Submit\\\\\\\">\\\\n</form>\\\\n</body>\\\\n</html>\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:host_webpage] Entering Tool run with input:\n",
      "\u001b[0m\"<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<title>AWS Workflows MCQ's</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>AWS Workflows MCQ's</h1>\n",
      "<form>\n",
      "<h2>1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments?</h2>\n",
      "<input type=\"radio\" name=\"q1\" value=\"a\"> a) AWS CloudFormation\n",
      "<input type=\"radio\" name=\"q1\" value=\"b\"> b) AWS CodeDeploy\n",
      "<input type=\"radio\" name=\"q1\" value=\"c\"> c) AWS CodePipeline\n",
      "<input type=\"radio\" name=\"q1\" value=\"d\"> d) AWS CloudTrail<br>\n",
      "<h2>2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications?</h2>\n",
      "<input type=\"radio\" name=\"q2\" value=\"a\"> a) AWS CodeBuild\n",
      "<input type=\"radio\" name=\"q2\" value=\"b\"> b) AWS CodeCommit\n",
      "<input type=\"radio\" name=\"q2\" value=\"c\"> c) AWS CodePipeline\n",
      "<input type=\"radio\" name=\"q2\" value=\"d\"> d) AWS CloudFormation<br>\n",
      "<h2>3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location?</h2>\n",
      "<input type=\"radio\" name=\"q3\" value=\"a\"> a) AWS CloudTrail\n",
      "<input type=\"radio\" name=\"q3\" value=\"b\"> b) AWS CloudWatch\n",
      "<input type=\"radio\" name=\"q3\" value=\"c\"> c) AWS Config\n",
      "<input type=\"radio\" name=\"q3\" value=\"d\"> d) AWS CloudFormation<br>\n",
      "<h2>4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud?</h2>\n",
      "<input type=\"radio\" name=\"q4\" value=\"a\"> a) AWS Cloud9\n",
      "<input type=\"radio\" name=\"q4\" value=\"b\"> b) AWS CodeBuild\n",
      "<input type=\"radio\" name=\"q4\" value=\"c\"> c) AWS CodeCommit\n",
      "<input type=\"radio\" name=\"q4\" value=\"d\"> d) AWS CodeDeploy<br>\n",
      "<h2>5. Which AWS tool allows you to define infrastructure as code using a declarative programming model?</h2>\n",
      "<input type=\"radio\" name=\"q5\" value=\"a\"> a) AWS CloudFormation\n",
      "<input type=\"radio\" name=\"q5\" value=\"b\"> b) AWS CodeDeploy\n",
      "<input type=\"radio\" name=\"q5\" value=\"c\"> c) AWS CodePipeline\n",
      "<input type=\"radio\" name=\"q5\" value=\"d\"> d) AWS CloudWatch<br>\n",
      "<input type=\"submit\" value=\"Submit\">\n",
      "</form>\n",
      "</body>\n",
      "</html>\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:host_webpage] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"http://localhost:5000/\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  \\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nYou are an user-friendly MCQ Generating Assistant. Answer the human message accordingly and generate multiple-choice questions (MCQs) as best you can.\\nalways follow these steps:\\n\\n1. Greet the user and ask for the source of the content for the questions (Upload a PDF document, Provide a URL to a web page, Enter text directly).\\n2. Based on the chosen source, take the appropriate action:\\n    - Upload: Call `upload_doc` with the user-uploaded document.\\n    - URL: Access the web page and extract content.\\n    - Text: Use the provided text directly.\\n3. Ask the user for the difficulty level of the questions (e.g., Easy, Medium, Hard).\\n4. Ask for the Topic and generate 5 Question on the selected topic.\\n5. Generate questions in a HTML form format.\\n6. Call `host_webpage` with the generated HTML code and provide the link to the user.\\n\\n\\nHuman: hi\\nAI: Hi! 👋  To get started, please tell me what you want to create MCQs from. Do you want to upload a document, provide a URL to a web page, or enter text directly?\\nHuman: i want to upload a document\\nAI: Great! Now, can you please tell me what topics are covered in the document you uploaded? I'll use this information to create some multiple-choice questions for you.\\nHuman: what are the topics available in document\\nAI: The topics available in the document are: aws workflows, aws redshift copy.\\nHuman: Okay generate mcq questions on aws workflows\\nAI: Amazon Managed Workflows for Apache Airflow (MWAA) is a managed service that simplifies the use of Apache Airflow, a popular workflow orchestration tool. It eliminates the need for installing and maintaining Airflow, allowing you to focus on defining and managing your workflows. MWAA provides features like automatic scaling, IAM-managed access, and private/public endpoints. It integrates seamlessly with other AWS services like Amazon S3 and Lambda, making it a robust solution for managing complex workflows.\\nHuman: can you generate mcq's on the same\\nAI: Sure! I can generate some MCQ's on AWS Workflows for you.  First, what difficulty level are you looking for? (Easy, Medium, Hard)  And what specific topic within AWS Workflows do you want to focus on?\\nHuman: generate medium type mcq's\\nAI: Okay, I can generate medium-difficulty MCQs on AWS Workflows.  To make sure I create the most relevant questions, could you tell me specifically what 'TOOLS' you want to focus on within AWS Workflows?  For example, are you interested in tools for managing workflows, monitoring workflows, or deploying workflows?\\nHuman: get revelent context and generate\\nAI: Sure, here are some medium-difficulty multiple-choice questions about AWS Workflows tools.  Remember, these questions are based on the context of AWS Workflows tools and their use in managing, monitoring, and deploying workflows.\\n\\n1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments? \\n   a) AWS CloudFormation\\n   b) AWS CodeDeploy\\n   c) AWS CodePipeline\\n   d) AWS CloudTrail\\n\\n2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications? \\n   a) AWS CodeBuild\\n   b) AWS CodeCommit\\n   c) AWS CodePipeline\\n   d) AWS CloudFormation\\n\\n3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location? \\n   a) AWS CloudTrail\\n   b) AWS CloudWatch\\n   c) AWS Config\\n   d) AWS CloudFormation\\n\\n4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud? \\n   a) AWS Cloud9\\n   b) AWS CodeBuild\\n   c) AWS CodeCommit\\n   d) AWS CodeDeploy\\n\\n5. Which AWS tool allows you to define infrastructure as code using a declarative programming model? \\n   a) AWS CloudFormation\\n   b) AWS CodeDeploy\\n   c) AWS CodePipeline\\n   d) AWS CloudWatch\\n\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> upload_doc: loads the document to memory. Use only when user mentioned i want to upload something       or else don't use.The input should always be an empty string.        and this function always returns status of the upload.\\n> get_topics_from_uploaded_document: Returns the topics in the uploaded documents, use this after     document loaded successfully.     The input should always be an empty string,     and this function will always return string of topics     .\\n> get_revelent_context: Returns the relevent context to generate questions, use this after     the user have choosed the topic to generate questions.     The input should always be an topic that user mentioned,     and this function will always return context string\\n> host_webpage: Returns the link where question webpage hosted, use this after     questions are generated in html form format.     The input should always be an html form code,     and this function will always return link to webpage hosted\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of upload_doc, get_topics_from_uploaded_document, get_revelent_context, host_webpage\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\ncan you host the same on webpage\\nAI: ```json\\n{\\n    \\\"action\\\": \\\"host_webpage\\\",\\n    \\\"action_input\\\": \\\"<!DOCTYPE html>\\\\n<html>\\\\n<head>\\\\n<title>AWS Workflows MCQ's</title>\\\\n</head>\\\\n<body>\\\\n<h1>AWS Workflows MCQ's</h1>\\\\n<form>\\\\n<h2>1. Which AWS tool is designed specifically for managing and automating cloud infrastructure deployments?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CloudFormation\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeDeploy\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodePipeline\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q1\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudTrail<br>\\\\n<h2>2. Which of the following AWS tools is primarily used for continuous integration and continuous delivery (CI/CD) of applications?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CodeBuild\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeCommit\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodePipeline\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q2\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudFormation<br>\\\\n<h2>3.  Which AWS tool allows you to monitor and manage your AWS resources in a centralized location?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CloudTrail\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CloudWatch\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS Config\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q3\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudFormation<br>\\\\n<h2>4. Which AWS tool provides a developer environment for building, running, and debugging applications in the cloud?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS Cloud9\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeBuild\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodeCommit\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q4\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CodeDeploy<br>\\\\n<h2>5. Which AWS tool allows you to define infrastructure as code using a declarative programming model?</h2>\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"a\\\\\\\"> a) AWS CloudFormation\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"b\\\\\\\"> b) AWS CodeDeploy\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"c\\\\\\\"> c) AWS CodePipeline\\\\n<input type=\\\\\\\"radio\\\\\\\" name=\\\\\\\"q5\\\\\\\" value=\\\\\\\"d\\\\\\\"> d) AWS CloudWatch<br>\\\\n<input type=\\\\\\\"submit\\\\\\\" value=\\\\\\\"Submit\\\\\\\">\\\\n</form>\\\\n</body>\\\\n</html>\\\"\\n}\\n```\\nHuman: TOOL RESPONSE: \\n---------------------\\nhttp://localhost:5000/\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\"\n",
      "  ]\n",
      "}\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:GoogleGenerativeAI] [1.85s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"I have hosted the MCQs on a webpage for you. You can access it at http://localhost:5000/.  Let me know if you have any other questions!\\\"\\n}\\n```\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.86s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"I have hosted the MCQs on a webpage for you. You can access it at http://localhost:5000/.  Let me know if you have any other questions!\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [7.78s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"I have hosted the MCQs on a webpage for you. You can access it at http://localhost:5000/.  Let me know if you have any other questions!\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Jul/2024 15:51:02] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "response=agent({\"input\": \"can you host the same on webpage\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
